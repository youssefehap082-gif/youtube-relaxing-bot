name: Auto Upload Very Long Relaxing Videos (2/day, 1h+)

on:
  schedule:
    - cron: '0 07 * * *'   # 07:00 UTC (morning upload)
    - cron: '0 19 * * *'   # 19:00 UTC (evening upload)
  workflow_dispatch:

jobs:
  upload_very_long:
    runs-on: ubuntu-latest
    timeout-minutes: 360

    steps:
      - name: Checkout repo
        uses: actions/checkout@v4

      - name: Install dependencies
        run: |
          sudo apt-get update -y
          sudo apt-get install -y jq curl ffmpeg

      - name: Prepare workspace
        run: |
          rm -rf clips long out || true
          mkdir -p clips long out

      - name: Fetch many clips (Pexels -> Pixabay -> Coverr)
        env:
          PEXELS_API_KEY: ${{ secrets.PEXELS_API_KEY }}
          PIXABAY_API_KEY: ${{ secrets.PIXABAY_API_KEY }}
          COVERR_API_KEY: ${{ secrets.COVERR_API_KEY }}
        run: |
          set -e
          TOPICS=("relaxing" "ocean" "rain" "forest" "waterfall" "clouds" "desert" "snow" "mountain" "river")
          QUERY=${TOPICS[$RANDOM % ${#TOPICS[@]}]}
          echo "Query chosen: $QUERY"

          urls=()

          # Try Pexels (collect many HD links)
          if [ -n "$PEXELS_API_KEY" ]; then
            PEX=$(curl -s -H "Authorization: $PEXELS_API_KEY" "https://api.pexels.com/videos/search?query=$QUERY&per_page=30")
            CNT=$(echo "$PEX" | jq '.videos | length' || echo 0)
            if [ "$CNT" -gt 0 ]; then
              for i in $(seq 0 11); do
                IDX=$((RANDOM % CNT))
                URL=$(echo "$PEX" | jq -r ".videos[$IDX].video_files[] | select(.quality==\"hd\") | .link" | head -n1)
                if [ -n "$URL" ] && [ "$URL" != "null" ]; then urls+=("$URL"); fi
              done
            fi
          fi

          # Pixabay fallback
          if [ "${#urls[@]}" -lt 6 ] && [ -n "$PIXABAY_API_KEY" ]; then
            PB=$(curl -s "https://pixabay.com/api/videos/?key=$PIXABAY_API_KEY&q=$QUERY&per_page=50")
            CNT2=$(echo "$PB" | jq '.hits | length' || echo 0)
            if [ "$CNT2" -gt 0 ]; then
              for i in $(seq 0 11); do
                IDX=$((RANDOM % CNT2))
                URL=$(echo "$PB" | jq -r ".hits[$IDX].videos.medium.url" | head -n1)
                if [ -n "$URL" ] && [ "$URL" != "null" ]; then urls+=("$URL"); fi
              done
            fi
          fi

          # Coverr fallback (if provided)
          if [ "${#urls[@]}" -lt 4 ] && [ -n "$COVERR_API_KEY" ]; then
            CV=$(curl -s -H "Authorization: Bearer $COVERR_API_KEY" "https://api.coverr.co/videos?per_page=30")
            for i in $(seq 0 5); do
              URL=$(echo "$CV" | jq -r ".data[$i].assets[0].url" 2>/dev/null || echo "")
              if [ -n "$URL" ]; then urls+=("$URL"); fi
            done
          fi

          # deduplicate and limit
          uniq_urls=($(printf "%s\n" "${urls[@]}" | awk '!seen[$0]++' | head -n 20))
          if [ ${#uniq_urls[@]} -eq 0 ]; then
            echo "No clips found from sources." >&2
            exit 1
          fi

          # Download up to 20 clips (we'll trim/use as needed)
          i=0
          for u in "${uniq_urls[@]}"; do
            if [ $i -ge 20 ]; then break; fi
            echo "Downloading clip $i: $u"
            curl -L "$u" -o "clips/clip_$i.mp4" --retry 3 --connect-timeout 20
            i=$((i+1))
          done

      - name: Build very long video (target 90 minutes; min 60m, max 120m) and ensure audio
        env:
          PIXABAY_API_KEY: ${{ secrets.PIXABAY_API_KEY }}
          MIXKIT_FALLBACK_AUDIO: ${{ secrets.MIXKIT_FALLBACK_AUDIO }}
        run: |
          set -e
          TARGET_MIN=3600     # 60 minutes
          TARGET_DESIRED=5400 # 90 minutes target (~1.5h)
          TARGET_MAX=7200     # 120 minutes max

          mkdir -p long
          rm -f long/list.txt || true
          TOTAL=0
          # Trim every clip to max 180s (3min) to build variety; add to concat list until reach TARGET_DESIRED
          for f in clips/*.mp4; do
            [ -f "$f" ] || continue
            outf="out_$(basename "$f")"
            ffmpeg -y -i "$f" -t 180 -c copy "long/$outf" >/dev/null 2>&1 || ffmpeg -y -i "$f" -t 180 -c copy "long/$outf"
            dur=$(ffprobe -v error -show_entries format=duration -of csv=p=0 "long/$outf" | cut -d. -f1)
            echo "file '$(pwd)/long/$outf'" >> long/list.txt
            TOTAL=$((TOTAL + dur))
            if [ "$TOTAL" -ge $TARGET_DESIRED ]; then break; fi
          done

          # If still under desired, loop first clip to reach between min and desired
          if [ "$TOTAL" -lt $TARGET_MIN ]; then
            echo "Total duration $TOTAL < $TARGET_MIN, looping first clip to extend"
            if [ -f "long/out_clip_0.mp4" ]; then
              ffmpeg -y -stream_loop -1 -i long/out_clip_0.mp4 -t $TARGET_DESIRED -c copy long/looped_combined.mp4
              mv long/looped_combined.mp4 long/final_combined.mp4
            else
              echo "Not enough source clips to loop." >&2
              exit 1
            fi
          else
            # concat
            ffmpeg -y -f concat -safe 0 -i long/list.txt -c copy long/final_combined.mp4
            # if final shorter than min, loop to reach min
            final_dur=$(ffprobe -v error -show_entries format=duration -of csv=p=0 long/final_combined.mp4 | cut -d. -f1)
            if [ "$final_dur" -lt $TARGET_MIN ]; then
              echo "Concated duration $final_dur < $TARGET_MIN, looping"
              ffmpeg -y -stream_loop -1 -i long/final_combined.mp4 -t $TARGET_DESIRED -c copy long/final_combined_looped.mp4
              mv long/final_combined_looped.mp4 long/final_combined.mp4
            fi
          fi

          # Ensure final is not longer than TARGET_MAX (trim if needed)
          ffmpeg -y -i long/final_combined.mp4 -t $TARGET_MAX -c copy long/final_video_tmp.mp4
          mv long/final_video_tmp.mp4 final_very_long.mp4

          echo "Checking audio in final..."
          if ! ffmpeg -i final_very_long.mp4 -af "volumedetect" -f null /dev/null 2>&1 | grep -q "mean_volume"; then
            echo "No audio detected -> try extract audio from Pixabay or add fallback"
            # Try get audio from Pixabay
            if [ -n "$PIXABAY_API_KEY" ]; then
              PB=$(curl -s "https://pixabay.com/api/videos/?key=$PIXABAY_API_KEY&q=rain&per_page=50")
              CNT=$(echo "$PB" | jq '.hits | length' || echo 0)
              if [ "$CNT" -gt 0 ]; then
                IDX=$((RANDOM % CNT))
                URL=$(echo "$PB" | jq -r ".hits[$IDX].videos.medium.url")
                curl -L "$URL" -o bg_video.mp4 || true
                if [ -f bg_video.mp4 ]; then
                  ffmpeg -y -i bg_video.mp4 -vn -ar 44100 -ac 2 -b:a 128k bg_audio.mp3
                  ffmpeg -y -i final_very_long.mp4 -i bg_audio.mp3 -shortest -c:v copy -c:a aac -b:a 128k final_very_long_with_audio.mp4
                  mv final_very_long_with_audio.mp4 final_very_long.mp4
                fi
              fi
            fi
          fi

          # fallback to mixkit audio if still no audio
          if ! ffmpeg -i final_very_long.mp4 -af "volumedetect" -f null /dev/null 2>&1 | grep -q "mean_volume"; then
            FALLBACK="${MIXKIT_FALLBACK_AUDIO:-https://assets.mixkit.co/music/preview/mixkit-relaxing-piano-628.mp3}"
            curl -L -o bg.mp3 "$FALLBACK" || true
            ffmpeg -y -stream_loop -1 -i bg.mp3 -i final_very_long.mp4 -shortest -c:v copy -c:a aac -b:a 128k final_very_long_with_audio.mp4
            mv final_very_long_with_audio.mp4 final_very_long.mp4
          fi

          echo "Final very long file ready:"
          ls -lh final_very_long.mp4
          ffprobe -v error -show_entries format=duration -of default=noprint_wrappers=1:nokey=1 final_very_long.mp4

      - name: Get YouTube access token
        id: get_token
        env:
          GOOGLE_CLIENT_ID: ${{ secrets.GOOGLE_CLIENT_ID }}
          GOOGLE_CLIENT_SECRET: ${{ secrets.GOOGLE_CLIENT_SECRET }}
          YT_REFRESH_TOKEN: ${{ secrets.YT_REFRESH_TOKEN }}
        run: |
          set -e
          resp=$(curl -s -d client_id="$GOOGLE_CLIENT_ID" -d client_secret="$GOOGLE_CLIENT_SECRET" -d refresh_token="$YT_REFRESH_TOKEN" -d grant_type=refresh_token https://oauth2.googleapis.com/token)
          ACCESS_TOKEN=$(echo "$resp" | jq -r .access_token)
          if [ -z "$ACCESS_TOKEN" ] || [ "$ACCESS_TOKEN" = "null" ]; then
            echo "Failed to get access token"; echo "$resp"; exit 1
          fi
          echo "access=$ACCESS_TOKEN" >> $GITHUB_OUTPUT

      - name: Create upload session & upload (resumable)
        env:
          ACCESS_TOKEN: ${{ steps.get_token.outputs.access }}
        run: |
          set -e
          # Titles tailored for long content
          TITLE_LIST=("Deep Relaxing Nature Sounds - Long Mix" "Calm Ocean & Waves - Extended" "Rainstorm for Sleep - Extended" "Forest Ambience Full Hour")
          TITLE=${TITLE_LIST[$RANDOM % ${#TITLE_LIST[@]}]}
          DESCRIPTION="Extended relaxing mix for sleep, meditation, and deep focus. Auto-uploaded. #relaxing #nature #sleep"
          jq -n --arg t "$TITLE" --arg d "$DESCRIPTION" '{"snippet":{"title":$t,"description":$d,"tags":["relaxing","nature","sleep","ambient"],"categoryId":"22"},"status":{"privacyStatus":"public"}}' > meta.json || true
          cat > meta.json <<EOF
{"snippet":{"title":"$TITLE","description":"$DESCRIPTION","tags":["relaxing","nature","sleep","ambient"],"categoryId":"22"},"status":{"privacyStatus":"public"}}
EOF

          curl -s -D headers.txt -o body.txt -X POST "https://www.googleapis.com/upload/youtube/v3/videos?uploadType=resumable&part=snippet,status" \
            -H "Authorization: Bearer $ACCESS_TOKEN" \
            -H "Content-Type: application/json; charset=UTF-8" \
            -d @meta.json

          UPLOAD_URL=$(grep -i '^Location:' headers.txt | awk '{print $2}' | tr -d '\r\n')
          if [ -z "$UPLOAD_URL" ]; then echo "Failed to get upload URL"; cat headers.txt; cat body.txt; exit 1; fi

          echo "Uploading final_very_long.mp4 (this may take a long time)..."
          curl -s -X PUT -T final_very_long.mp4 -H "Content-Type: application/octet-stream" "$UPLOAD_URL" -o upload_result.json
          cat upload_result.json

